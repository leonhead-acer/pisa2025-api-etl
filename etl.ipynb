{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare / Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Maple Data and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from etl.prepare import *\n",
    "\n",
    "with open('./config.yaml', 'r') as file:\n",
    "    config_data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>item_order</th>\n",
       "      <th>db_resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLA25SP1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLA25SP2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLA25SP3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLA25SP4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10560004005</td>\n",
       "      <td>FLA25SP2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         login   unit_id item_order db_resp\n",
       "0  10560004001  FLA25SP1          1       4\n",
       "1  10560004001  FLA25SP2          2     4.5\n",
       "2  10560004001  FLA25SP3          3     4.5\n",
       "3  10560004001  FLA25SP4          4       5\n",
       "4  10560004005  FLA25SP2          2       4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import itertools\n",
    "\n",
    "params = config_data['ams']\n",
    "\n",
    "with psycopg2.connect(\n",
    "    f\"dbname={params['database']} user={params['username']} host={params['host']} port = {params['port']} password = {params['password']}\",\n",
    "    cursor_factory=RealDictCursor\n",
    ") as con:\n",
    "\n",
    "    with con.cursor() as cur:\n",
    "        cur.execute(\n",
    "            f\"\"\"\n",
    "            SELECT student_login as login, item_code as unit_id,criteria_1 as db_resp, right(item_code,1) as item_order\n",
    "                FROM \"mv_pisa_single_results\"\n",
    "                WHERE item_code ~ '^FLA';\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        ams_data = pd.DataFrame(cur.fetchall()).rename(columns={'unit_id': 'unit_id'})\n",
    "        ams_data = ams_data.astype('string')\n",
    "        ams_data['db_resp'] = ams_data['db_resp'].apply(lambda x: x.rstrip('0').rstrip('.'))\n",
    "\n",
    "        dat = pd.DataFrame(itertools.product(list(ams_data.login.unique()),[\"FLA25SP\" + str(x + 1) for x in range(0,4)]),columns = ['login','unit_id']).sort_values('login').assign(db_resp = '9')\n",
    "        dat['item_order'] = dat['unit_id'].apply(lambda x: x[-1:])\n",
    "\n",
    "        ams_data = pd.merge(dat, ams_data, on=['login','unit_id','item_order'], how='outer', suffixes=('_dat', '_ams'))\n",
    "        ams_data['db_resp'] = ams_data['db_resp_ams'].combine_first(ams_data['db_resp_dat'])\n",
    "        ams_data.drop(columns=['db_resp_dat','db_resp_ams'],inplace=True)\n",
    "\n",
    "        recode_tab = pd.DataFrame(\n",
    "            {\n",
    "                'original': list(range(1,14,1),),\n",
    "                'new': [x * 0.5 for x in range(0,13,1)]\n",
    "            }\n",
    "        )\n",
    "\n",
    "ams_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.extract import *\n",
    "from etl.transform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = '2'\n",
    "\n",
    "with postgresql_conn(params = config_data['postgresql_prod']) as conn:\n",
    "    conn.autocommit = True\n",
    "    with conn.cursor() as cur:\n",
    "        # student_participants = extract_student_participants(filepath = '../maple-s3/participants_post.xlsx')\n",
    "        cur.execute(\"SELECT * FROM maple.isot_table\")\n",
    "        isot_table = pd.DataFrame(cur.fetchall()).drop_duplicates('isocntcd',keep = 'last')\n",
    "        isot_table.loc[isot_table['isoalpha3'] == 'QBR',['isoalpha3']] = 'BEL'\n",
    "        isot_table.loc[isot_table['isoalpha3'] == 'TWN',['isoalpha3']] = 'TAP'\n",
    "        cur.execute(\"SELECT * FROM maple.maple_student_post_val\")\n",
    "        student_participants_post = pd.DataFrame(cur.fetchall())\n",
    "        student_participants_post['username'] = student_participants_post['username'].astype(str)\n",
    "        student_participants_post['isocntcd'] = student_participants_post['username'].str.slice(1,4)\n",
    "        student_participants_post.loc[student_participants_post['isoalpha3'].isin(['QBL','QBR']),['isoalpha3']] = 'BEL'\n",
    "\n",
    "        countries_all = isot_table.isoalpha3.unique()\n",
    "        countries_now = list(student_participants_post.loc[student_participants_post['batch'] == batch_num,:].isoalpha3.unique())\n",
    "        countries_post = list(student_participants_post.loc[student_participants_post['batch'] != batch_num,:].isoalpha3.unique())\n",
    "        countries_pre_init = list(set(countries_all) - set(countries_now) - set(countries_post))\n",
    "\n",
    "        student_participants_pre = pd.read_excel('../maple-s3/participants_with_entity.xlsx').drop_duplicates(['username'],keep = 'last')\n",
    "        student_participants_pre['username'] = student_participants_pre['username'].astype(str)\n",
    "        student_participants_pre['isocntcd'] = student_participants_pre['username'].str.slice(1,4)\n",
    "        student_participants_pre = student_participants_pre.loc[student_participants_pre['isoalpha3'].isin(countries_pre_init)].drop_duplicates(subset = ['username'],keep = 'last')\n",
    "        student_participants_pre['login'] = student_participants_pre['username']\n",
    "        student_participants_pre = student_participants_pre.rename({'testAttendance':'test_attendance','questionnaireAttendance': 'questionnaire_attendance'},axis = 1)\n",
    "        countries_pre = list(set(student_participants_pre.isoalpha3.unique()) - set(['GBR']))\n",
    "\n",
    "        student_participants = pd.concat(\n",
    "            [\n",
    "                student_participants_pre,\n",
    "                student_participants_post\n",
    "            ],\n",
    "            axis = 0\n",
    "        )\n",
    "\n",
    "        student_participants['schid'] = student_participants['username'].str.slice(4,8).str.lstrip('0').astype(int)\n",
    "\n",
    "        conditions = [\n",
    "            (student_participants['schid'] <= 118) & (student_participants['isoalpha3'] == 'BEL'),\n",
    "            (student_participants['schid'] >= 119) & (student_participants['isoalpha3'] == 'BEL')\n",
    "        ]\n",
    "\n",
    "        codes_cnt = [\n",
    "            'QBL',\n",
    "            'QBR'\n",
    "        ]\n",
    "\n",
    "        codes_name = [\n",
    "            'Belgium (Flemish)',\n",
    "            'Belgium (French)'\n",
    "        ]\n",
    "\n",
    "        student_participants['isoalpha3_new'] = np.select(conditions,codes_cnt,student_participants['isoalpha3'])\n",
    "        student_participants = student_participants.drop(columns = ['isoalpha3']).rename({'isoalpha3_new':'isoalpha3'},axis = 1)\n",
    "\n",
    "        student_participants['isoname_new'] = np.select(conditions,codes_name,student_participants['isoname'])\n",
    "        student_participants = student_participants.drop(columns = ['isoname']).rename({'isoname_new':'isoname'},axis = 1)\n",
    "        \n",
    "        nc_dat_now = isot_table.loc[isot_table['isoalpha3'].isin(countries_now)].assign(process='now')\n",
    "        nc_dat_post = isot_table.loc[isot_table['isoalpha3'].isin(countries_post)].assign(process='post')\n",
    "        nc_dat_pre = isot_table.loc[isot_table['isoalpha3'].isin(countries_pre)].assign(process='pre')  \n",
    "        nc_dat = pd.concat(\n",
    "            [\n",
    "                nc_dat_post,\n",
    "                nc_dat_now,\n",
    "                nc_dat_pre\n",
    "            ],\n",
    "            axis = 0\n",
    "        )\n",
    "        # nc_dat = extract_country_codes(filepath = './data/maple-s3/ISOT_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fla_s_dat = pd.merge(\n",
    "    student_participants.loc[:,['login','isoalpha3']],\n",
    "    ams_data,\n",
    "    on = 'login',\n",
    "    how = 'inner'\n",
    ").astype('string').assign(in_cq = '1')\n",
    "\n",
    "fla_s_dat.loc[fla_s_dat['in_cq']=='1',:].groupby(['unit_id','db_resp','isoalpha3']).size().unstack(fill_value=0).to_excel(f'./data/FLASpeaking_freq_Resp_byCnt_{datetime.date.today().strftime('%Y%m%d')}.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'etl.load'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43metl.load\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'etl.load'"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['etl.load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_dat2 = nc_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_form_dat = pd.read_csv(\n",
    "    \"./data/delivery_results_test_form.csv\"\n",
    ").rename(columns={\"testqtilabel\": \"testQtiLabel\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting codebook data from sheet FLA_Reading_CQ\n",
      "Extracting codebook data from sheet FLA_Listening_CQ\n",
      "Codebook created for FLA\n",
      "Processing data for: AUT\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: BRN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: QCY\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 45001\n",
      "Actual rows: 45001\n",
      "Rows before merge test form:  45001\n",
      "Step 6: rows = 45001 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_QCY.json: 18.56 seconds\n",
      "Processing data for: DEU\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 62245\n",
      "Actual rows: 62245\n",
      "Rows before merge test form:  62245\n",
      "Step 6: rows = 62245 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_DEU.json: 64.60 seconds\n",
      "Processing data for: DNK\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (2,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 44865\n",
      "Actual rows: 44865\n",
      "Rows before merge test form:  44865\n",
      "Step 6: rows = 44865 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_DNK.json: 18.01 seconds\n",
      "Processing data for: QUK\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: QSC\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: HRV\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (2,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 78649\n",
      "Actual rows: 78649\n",
      "Rows before merge test form:  78649\n",
      "Step 6: rows = 78649 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_HRV.json: 47.16 seconds\n",
      "Processing data for: HUN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: IDN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: IRL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: ITA\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 64804\n",
      "Actual rows: 64804\n",
      "Rows before merge test form:  64804\n",
      "Step 6: rows = 64804 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_ITA.json: 38.61 seconds\n",
      "Processing data for: LTU\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MAC\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MNE\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MNG\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: NLD\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 32158\n",
      "Actual rows: 32158\n",
      "Rows before merge test form:  32158\n",
      "Step 6: rows = 32158 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_NLD.json: 16.96 seconds\n",
      "Processing data for: POL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: PRT\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 72845\n",
      "Actual rows: 72845\n",
      "Rows before merge test form:  72845\n",
      "Step 6: rows = 72845 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_PRT.json: 81.32 seconds\n",
      "Processing data for: QAT\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (2,9,13,15,16,18,21,22,27,28,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 67161\n",
      "Actual rows: 67161\n",
      "Rows before merge test form:  67161\n",
      "Step 6: rows = 67161 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_QAT.json: 35.13 seconds\n",
      "Processing data for: SAU\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SGP\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SRB\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SVN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SWE\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 65454\n",
      "Actual rows: 65454\n",
      "Rows before merge test form:  65454\n",
      "Step 6: rows = 65454 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_SWE.json: 31.78 seconds\n",
      "Processing data for: TUR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: URY\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: ARM\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: AUS\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: BEL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 53429\n",
      "Actual rows: 53429\n",
      "Rows before merge test form:  53429\n",
      "Step 6: rows = 53429 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_BEL.json: 69.54 seconds\n",
      "Processing data for: BGR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (2,4,5,8,9,13,15,16,18,20,21,22,27,28,29,33,34,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 81947\n",
      "Actual rows: 81947\n",
      "Rows before merge test form:  81947\n",
      "Step 6: rows = 81947 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_BGR.json: 28.23 seconds\n",
      "Processing data for: CAN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: CHE\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: COL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 62377\n",
      "Actual rows: 62377\n",
      "Rows before merge test form:  62377\n",
      "Step 6: rows = 62377 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_COL.json: 107.54 seconds\n",
      "Processing data for: CZE\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33,34,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 65351\n",
      "Actual rows: 65351\n",
      "Rows before merge test form:  65351\n",
      "Step 6: rows = 65351 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_CZE.json: 100.63 seconds\n",
      "Processing data for: ECU\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: ESP\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 160250\n",
      "Actual rows: 160250\n",
      "Rows before merge test form:  160250\n",
      "Step 6: rows = 160250 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_ESP.json: 187.54 seconds\n",
      "Processing data for: EST\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: FIN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 61802\n",
      "Actual rows: 61802\n",
      "Rows before merge test form:  61802\n",
      "Step 6: rows = 61802 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_FIN.json: 65.18 seconds\n",
      "Processing data for: FRA\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (2,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 59799\n",
      "Actual rows: 59799\n",
      "Rows before merge test form:  59799\n",
      "Step 6: rows = 59799 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_FRA.json: 105.91 seconds\n",
      "Processing data for: GEO\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: GRC\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (2,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 60729\n",
      "Actual rows: 60729\n",
      "Rows before merge test form:  60729\n",
      "Step 6: rows = 60729 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_GRC.json: 23.00 seconds\n",
      "Processing data for: ISL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: ISR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 41092\n",
      "Actual rows: 41092\n",
      "Rows before merge test form:  41092\n",
      "Step 6: rows = 41092 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_ISR.json: 67.05 seconds\n",
      "Processing data for: JOR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: JPN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: KAZ\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: KEN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: KHM\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: KOR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: LUX\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: LVA\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MAR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MLT\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: NOR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: PHL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: PSE\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: ROU\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 69152\n",
      "Actual rows: 69152\n",
      "Rows before merge test form:  69152\n",
      "Step 6: rows = 69152 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_ROU.json: 129.02 seconds\n",
      "Processing data for: RWA\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: TAP\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (2,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 63839\n",
      "Actual rows: 63839\n",
      "Rows before merge test form:  63839\n",
      "Step 6: rows = 63839 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_TAP.json: 88.51 seconds\n",
      "Processing data for: UKR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\3984927582.py:55: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(filepath_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected rows: 59196\n",
      "Actual rows: 59196\n",
      "Rows before merge test form:  59196\n",
      "Step 6: rows = 59196 & columns = 52\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/post/FLA_UKR.json: 19.49 seconds\n",
      "Processing data for: USA\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: UZB\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: VNM\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: ALB\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: ARG\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: BRA\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: CHL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: CRI\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: GTM\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: HKG\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: KGZ\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: LBN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MDA\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MUS\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MYS\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: NZL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: PER\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Expected rows: 9539\n",
      "Actual rows: 9539\n",
      "Rows before merge test form:  9539\n",
      "Step 6: rows = 9539 & columns = 53\n",
      "Extracting SQL query checks...\n",
      "Time taken for ./data/db/fla/pre/FLA_PER.json: 23.69 seconds\n",
      "Processing data for: PRY\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SLV\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SVK\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: THA\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: TJK\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "count = 0\n",
    "domain_all = [\"FLA\"]\n",
    "\n",
    "for domain in domain_all:\n",
    "    cbk = create_codebook(domain = domain)\n",
    "    \n",
    "    if(domain == 'FLA'):\n",
    "        gap_vars = True\n",
    "\n",
    "    for idr,row in nc_dat2.iterrows():\n",
    "        start_time = time.time()\n",
    "        country_print = str(row['isoalpha3'])\n",
    "        print(f\"Processing data for: {country_print}\")\n",
    "\n",
    "        extract_json(domain = domain, nc_dat = row ,overwrite = False, con = postgresql_conn(params = config_data['postgresql_prod']))\n",
    "\n",
    "        sub_fold = 'pre' if row['process'] == 'pre' else 'post'\n",
    "\n",
    "        filepath = f\"./data/db/{domain.lower()}/{sub_fold}/{domain}_{country_print}.json\"\n",
    "\n",
    "        if(os.path.isfile(filepath)):\n",
    "\n",
    "            filepath_csv = f\"./data/db/{domain.lower()}/{sub_fold}/{domain}_{country_print}.csv\"\n",
    "\n",
    "            # df = read_json_file(filepath)\n",
    "            # print(\"Step 1: rows = \" + str(df.shape[0]) + ' & columns = ' + str(df.shape[1]))\n",
    "            \n",
    "            # df1 = explode_raw_data(df = df)\n",
    "            # print(\"Step 2: rows = \" + str(df1.shape[0]) + ' & columns = ' + str(df1.shape[1]))\n",
    "\n",
    "            # df3 = explode_items(df1)\n",
    "            # print(\"Step 3: rows = \" + str(df3.shape[0]) + ' & columns = ' + str(df3.shape[1]))\n",
    "\n",
    "            # df4 = explode_values(df3)\n",
    "            # df4 = rename_variables(df4, domain = domain)\n",
    "            # df4 = check_duplicates(df4)\n",
    "            # df4 = replace_blank_json(df4)\n",
    "            # print(\"Step 4: rows = \" + str(df4.shape[0]) + ' & columns = ' + str(df4.shape[1]))\n",
    "\n",
    "            # df6 = explode_responses(df4, domain = domain)\n",
    "            # if(domain == 'FLA'):\n",
    "            #     df6 = fla_recode_FLALDTB1002(df6)\n",
    "            #     df6 = gap_recode(df6,cbk)\n",
    "            #     df6 = rmmb_recode(df6,cbk)\n",
    "            # print(\"Step 5: rows = \" + str(df6.shape[0]) + ' & columns = ' + str(df6.shape[1]))\n",
    "\n",
    "            # df8 = merge_cbk_status(df6,cbk,domain,ams_data)\n",
    "            # df8 = time_var_recode(df8)\n",
    "            # df8 = score_resp_recode(df8,domain = 'FLA') \n",
    "            # df8 = trailing_missing(df8)\n",
    "            # df8 = cmc_item_create(df8,cbk=cbk, domain = 'FLA')\n",
    "            # df8.to_csv(filepath_csv)\n",
    "            df8 = pd.read_csv(filepath_csv)\n",
    "            df9 = merge_participant_info(df8,student_participants=student_participants)\n",
    "            print(\"Rows before merge test form: \",str(df9.shape[0]))\n",
    "            df9 = pd.merge(\n",
    "                df9,\n",
    "                test_form_dat,\n",
    "                how = 'left',\n",
    "                on = ['login','testQtiLabel']\n",
    "            )\n",
    "            print(\"Step 6: rows = \" + str(df9.shape[0]) + ' & columns = ' + str(df9.shape[1]))\n",
    "\n",
    "            df_resp_check = sql_query_ge(nc_dat = row,cbk = cbk,con = postgresql_conn(params = config_data['postgresql_prod']))\n",
    "\n",
    "            if(count == 0):\n",
    "                df_long = df9\n",
    "                df_long_check = df_resp_check\n",
    "            else:\n",
    "                df_long = pd.concat([df_long,df9],axis = 0)\n",
    "                df_long_check = pd.concat([df_long_check,df_resp_check],axis = 0)\n",
    "\n",
    "            if(row['isoalpha3'] != 'PER'):\n",
    "                df_long_check = df_long_check.loc[df_long_check['unit_id'] != 'FLARMMB2001']\n",
    "            \n",
    "            count =+ 1\n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f\"Time taken for {filepath}: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # df9.export_to_postgresql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>login</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>testQtiLabel</th>\n",
       "      <th>sessionStartTime</th>\n",
       "      <th>sessionEndTime</th>\n",
       "      <th>language</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>itemId</th>\n",
       "      <th>...</th>\n",
       "      <th>mpop1</th>\n",
       "      <th>ppart1</th>\n",
       "      <th>isoalpha3</th>\n",
       "      <th>isoname</th>\n",
       "      <th>isocntcd</th>\n",
       "      <th>test_attendance</th>\n",
       "      <th>questionnaire_attendance</th>\n",
       "      <th>batch</th>\n",
       "      <th>test_form</th>\n",
       "      <th>level_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11960037071</td>\n",
       "      <td>1711439509263.0</td>\n",
       "      <td>FLA-R-M6-FLA-R-H3-FLA-R-L2</td>\n",
       "      <td>2024-03-26 18:51:21</td>\n",
       "      <td>2024-03-26 18:51:47</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLARDGSA2006</td>\n",
       "      <td>cluster1-FLAR09-item-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QCY</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B087</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11960011035</td>\n",
       "      <td>1711526279566.0</td>\n",
       "      <td>FLA-R-M6-FLA-R-H3-FLA-R-L2</td>\n",
       "      <td>2024-03-27 18:44:46</td>\n",
       "      <td>2024-03-27 18:57:57</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLARDGSA2006</td>\n",
       "      <td>cluster1-FLAR09-item-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QCY</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B087</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11960040018</td>\n",
       "      <td>1721739530332.0</td>\n",
       "      <td>FLA-R-M6-FLA-R-H3-FLA-R-L2</td>\n",
       "      <td>2024-04-03 17:33:27</td>\n",
       "      <td>2024-04-03 17:57:30</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLARDGSA2006</td>\n",
       "      <td>cluster1-FLAR09-item-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QCY</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B087</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11960044002</td>\n",
       "      <td>1721739606878.0</td>\n",
       "      <td>FLA-R-M6-FLA-R-H3-FLA-R-L2</td>\n",
       "      <td>2024-04-03 16:38:52</td>\n",
       "      <td>2024-04-03 16:45:40</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLARDGSA2006</td>\n",
       "      <td>cluster1-FLAR09-item-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QCY</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B087</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11960013042</td>\n",
       "      <td>1721741991024.0</td>\n",
       "      <td>FLA-R-M6-FLA-R-H3-FLA-R-L2</td>\n",
       "      <td>2024-04-12 16:34:10</td>\n",
       "      <td>2024-04-12 16:37:54</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLARDGSA2006</td>\n",
       "      <td>cluster1-FLAR09-item-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>QCY</td>\n",
       "      <td>Cyprus</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B087</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 index        login last_update_date                testQtiLabel  \\\n",
       "0          0   0.0  11960037071  1711439509263.0  FLA-R-M6-FLA-R-H3-FLA-R-L2   \n",
       "1          1   1.0  11960011035  1711526279566.0  FLA-R-M6-FLA-R-H3-FLA-R-L2   \n",
       "2          2   2.0  11960040018  1721739530332.0  FLA-R-M6-FLA-R-H3-FLA-R-L2   \n",
       "3          3   3.0  11960044002  1721739606878.0  FLA-R-M6-FLA-R-H3-FLA-R-L2   \n",
       "4          4   4.0  11960013042  1721741991024.0  FLA-R-M6-FLA-R-H3-FLA-R-L2   \n",
       "\n",
       "      sessionStartTime       sessionEndTime language       unit_id  \\\n",
       "0  2024-03-26 18:51:21  2024-03-26 18:51:47    en-ZZ  FLARDGSA2006   \n",
       "1  2024-03-27 18:44:46  2024-03-27 18:57:57    en-ZZ  FLARDGSA2006   \n",
       "2  2024-04-03 17:33:27  2024-04-03 17:57:30    en-ZZ  FLARDGSA2006   \n",
       "3  2024-04-03 16:38:52  2024-04-03 16:45:40    en-ZZ  FLARDGSA2006   \n",
       "4  2024-04-12 16:34:10  2024-04-12 16:37:54    en-ZZ  FLARDGSA2006   \n",
       "\n",
       "                   itemId  ... mpop1 ppart1 isoalpha3 isoname isocntcd  \\\n",
       "0  cluster1-FLAR09-item-1  ...     1      1       QCY  Cyprus      196   \n",
       "1  cluster1-FLAR09-item-1  ...     1      1       QCY  Cyprus      196   \n",
       "2  cluster1-FLAR09-item-1  ...     1      1       QCY  Cyprus      196   \n",
       "3  cluster1-FLAR09-item-1  ...     1      1       QCY  Cyprus      196   \n",
       "4  cluster1-FLAR09-item-1  ...     1      1       QCY  Cyprus      196   \n",
       "\n",
       "  test_attendance questionnaire_attendance batch test_form level_0  \n",
       "0               1                        1     1      B087    <NA>  \n",
       "1               1                        1     1      B087    <NA>  \n",
       "2               1                        1     1      B087    <NA>  \n",
       "3               1                        1     1      B087    <NA>  \n",
       "4               1                        1     1      B087    <NA>  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = df_long.copy(deep = True)\n",
    "df_check = df_check.astype('string')\n",
    "df_check = df_check.loc[df_check['in_cq'] == '1',:]\n",
    "df_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\leon.head\\AppData\\Local\\Temp\\1\\ipykernel_11436\\456698245.py:16: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  df_check_sum_score = df_check_sum_score.groupby(['username','unit_id','score']).agg({'score_check':sum}).reset_index(inplace=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>score</th>\n",
       "      <th>score_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLAL5IMCB1001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLALDGA1001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLALDGA1002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLALDGA1003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10560004001</td>\n",
       "      <td>FLALDGA1004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username        unit_id  score  score_check\n",
       "0  10560004001  FLAL5IMCB1001    4.0            4\n",
       "1  10560004001    FLALDGA1001    1.0            1\n",
       "2  10560004001    FLALDGA1002    1.0            1\n",
       "3  10560004001    FLALDGA1003    1.0            1\n",
       "4  10560004001    FLALDGA1004    1.0            1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summ_config = {}\n",
    "\n",
    "conditions = [\n",
    "    df_check['score_code'].eq('1').astype(bool),\n",
    "    df_check['score_code'].eq('0').astype(bool),\n",
    "    df_check['score_code'].eq('9').astype(bool),\n",
    "]\n",
    "codes = [\n",
    "    1,0,0\n",
    "]\n",
    "\n",
    "df_check_sum_score = df_check.copy(deep = True)\n",
    "df_check_sum_score\n",
    "df_check_sum_score['score_check'] = np.select(conditions,codes,None)\n",
    "\n",
    "df_check_sum_score = df_check_sum_score.groupby(['username','unit_id','score']).agg({'score_check':sum}).reset_index(inplace=False)\n",
    "df_check_sum_score = df_check_sum_score[~df_check_sum_score['unit_id'].isin(cbk.loc[cbk['resp_cat'].str.contains('gap',na=False)].unit_id.unique().tolist())]\n",
    "df_check_sum_score[['score','score_check']] = df_check_sum_score[['score','score_check']].apply(pd.to_numeric)\n",
    "\n",
    "df_summ_config[\"df_check_sum_score\"] = \"config_check_sum_score\"\n",
    "\n",
    "df_check_sum_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>score</th>\n",
       "      <th>score_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>10560004012</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>10560004017</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>10560004024</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>10560004043</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>10560004071</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437711</th>\n",
       "      <td>18040182012</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437873</th>\n",
       "      <td>18040182029</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437915</th>\n",
       "      <td>18040182036</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437998</th>\n",
       "      <td>18040182047</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438493</th>\n",
       "      <td>18040188016</td>\n",
       "      <td>FLALDGA2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6752 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           username      unit_id  score  score_check\n",
       "101     10560004012  FLALDGA2014    0.0            1\n",
       "152     10560004017  FLALDGA2014    0.0            1\n",
       "206     10560004024  FLALDGA2014    0.0            1\n",
       "335     10560004043  FLALDGA2014    0.0            1\n",
       "584     10560004071  FLALDGA2014    0.0            1\n",
       "...             ...          ...    ...          ...\n",
       "437711  18040182012  FLALDGA2014    0.0            1\n",
       "437873  18040182029  FLALDGA2014    0.0            1\n",
       "437915  18040182036  FLALDGA2014    0.0            1\n",
       "437998  18040182047  FLALDGA2014    0.0            1\n",
       "438493  18040188016  FLALDGA2014    1.0            0\n",
       "\n",
       "[6752 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check_sum_score.loc[df_check_sum_score['score'].astype(int) != df_check_sum_score['score_check'].astype(int),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summ_config[\"df_check\"] = \"config_df_check\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>column</th>\n",
       "      <th>dimension</th>\n",
       "      <th>status</th>\n",
       "      <th>expectation_type</th>\n",
       "      <th>unexpected_count</th>\n",
       "      <th>element_count</th>\n",
       "      <th>unexpected_percent</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_check_sum_score</td>\n",
       "      <td>score; score_check</td>\n",
       "      <td>Validity</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>expect_column_pair_values_to_be_equal</td>\n",
       "      <td>6752</td>\n",
       "      <td>424948</td>\n",
       "      <td>1.5889</td>\n",
       "      <td>98.4111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_check_sum_score</td>\n",
       "      <td>username</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_values_to_not_be_null</td>\n",
       "      <td>0</td>\n",
       "      <td>424948</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df_check_sum_score</td>\n",
       "      <td>username</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_value_lengths_to_equal</td>\n",
       "      <td>0</td>\n",
       "      <td>424948</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df_check_sum_score</td>\n",
       "      <td>score</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_values_to_not_be_null</td>\n",
       "      <td>0</td>\n",
       "      <td>424948</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_check</td>\n",
       "      <td>username</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_values_to_not_be_null</td>\n",
       "      <td>0</td>\n",
       "      <td>694081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_check</td>\n",
       "      <td>username</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_value_lengths_to_equal</td>\n",
       "      <td>0</td>\n",
       "      <td>694081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df_check</td>\n",
       "      <td>qtiLabel</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_values_to_be_in_set</td>\n",
       "      <td>0</td>\n",
       "      <td>694081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                table              column     dimension  status  \\\n",
       "0  df_check_sum_score  score; score_check      Validity  FAILED   \n",
       "1  df_check_sum_score            username  Completeness  PASSED   \n",
       "2  df_check_sum_score            username  Completeness  PASSED   \n",
       "3  df_check_sum_score               score  Completeness  PASSED   \n",
       "0            df_check            username  Completeness  PASSED   \n",
       "1            df_check            username  Completeness  PASSED   \n",
       "2            df_check            qtiLabel  Completeness  PASSED   \n",
       "\n",
       "                        expectation_type  unexpected_count  element_count  \\\n",
       "0  expect_column_pair_values_to_be_equal              6752         424948   \n",
       "1    expect_column_values_to_not_be_null                 0         424948   \n",
       "2   expect_column_value_lengths_to_equal                 0         424948   \n",
       "3    expect_column_values_to_not_be_null                 0         424948   \n",
       "0    expect_column_values_to_not_be_null                 0         694081   \n",
       "1   expect_column_value_lengths_to_equal                 0         694081   \n",
       "2      expect_column_values_to_be_in_set                 0         694081   \n",
       "\n",
       "   unexpected_percent   percent  \n",
       "0              1.5889   98.4111  \n",
       "1              0.0000  100.0000  \n",
       "2              0.0000  100.0000  \n",
       "3              0.0000  100.0000  \n",
       "0              0.0000  100.0000  \n",
       "1              0.0000  100.0000  \n",
       "2              0.0000  100.0000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from test.data_quality.DataQuality import DataQuality\n",
    "from test.utils.utils import create_df_from_dq_results\n",
    "\n",
    "df_summ_tab = []\n",
    "\n",
    "for k, v in df_summ_config.items():\n",
    "    dq = DataQuality(globals()[k],config_path=f\"./test/config/{v}.json\")\n",
    "    dq_results = dq.run_test()\n",
    "    dq_table = create_df_from_dq_results(dq_results=dq_results).assign(table=k)\n",
    "    cols = dq_table.columns.to_list()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "    df_summ_tab.append(dq_table[cols])\n",
    "\n",
    "dq_table_all = pd.concat(df_summ_tab)\n",
    "dq_table_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>testQtiLabel</th>\n",
       "      <th>qtiLabel</th>\n",
       "      <th>db_resp</th>\n",
       "      <th>score_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43314</th>\n",
       "      <td>11960015030</td>\n",
       "      <td>FLA-S-5</td>\n",
       "      <td>FLAS304</td>\n",
       "      <td>9</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43315</th>\n",
       "      <td>11960015030</td>\n",
       "      <td>FLA-S-5</td>\n",
       "      <td>FLAS103</td>\n",
       "      <td>9</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43316</th>\n",
       "      <td>11960015030</td>\n",
       "      <td>FLA-S-5</td>\n",
       "      <td>FLAS203</td>\n",
       "      <td>9</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43317</th>\n",
       "      <td>11960015030</td>\n",
       "      <td>FLA-S-5</td>\n",
       "      <td>FLAS404</td>\n",
       "      <td>9</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             login testQtiLabel qtiLabel db_resp score_code\n",
       "43314  11960015030      FLA-S-5  FLAS304       9          r\n",
       "43315  11960015030      FLA-S-5  FLAS103       9          r\n",
       "43316  11960015030      FLA-S-5  FLAS203       9          r\n",
       "43317  11960015030      FLA-S-5  FLAS404       9          r"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_S = df_long.loc[df_long['domain'] == 'FLA-S',:]\n",
    "login_test = df_S.loc[df_S['score_code'] == 'r','login'].drop_duplicates(keep = 'first').iloc[5]\n",
    "# login_test = '15280016015'\n",
    "\n",
    "df_x = df_long.loc[(df_long['login'] == login_test) & (df_long['domain'] == 'FLA-S'),['login','testQtiLabel','qtiLabel','db_resp','score_code']]\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2238\n"
     ]
    }
   ],
   "source": [
    "log_list = df_S.login.unique()\n",
    "count = 0\n",
    "for log in log_list:\n",
    "    four_rows = df_S.loc[df_S['login'] == log,:].shape[0] == 4\n",
    "    r_score = any(df_S.loc[df_S['login'] == log,:].score_code == 'r')\n",
    "    if(four_rows and r_score):\n",
    "        count +=1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2238"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_S.loc[df_S['score_code'] == 'r','login'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12500013045', '12500015031', '12500074013', '16040013008',\n",
       "       '16040013023', '16040013027', '16040013035', '16040019077',\n",
       "       '16040036050', '16040036065', '16040036069', '16040036077',\n",
       "       '16040036081', '16040036088', '16040037059', '16040037065',\n",
       "       '16040040026', '16040040054', '16040040061', '16040061041',\n",
       "       '16040061072', '16040070004', '16040070016', 'A16040100086',\n",
       "       'A16040013046', '16040007006', '16040007012', '16040004037',\n",
       "       '16040004049', '16040004033', '16040058021', '16040058009',\n",
       "       '16040058033', '16040058063', '16040058014', '16040058068',\n",
       "       '16040058002', '16040058026', '16040058080', '16040058052',\n",
       "       '16040058091', '16040058056', '16040058044', '16040058037',\n",
       "       '16040058087', '16040058075', '16040079020', '16040079027',\n",
       "       '16040079001', '16040079039', '16040079051', '16040079032',\n",
       "       '16040079055', '16040079043', '16040031057', '16040028025',\n",
       "       '16040028008', '16040028001', '16040028074', '16040028067',\n",
       "       '16040028020', '16040028013', '16040028086', '16040028043',\n",
       "       '16040028036', '16040028048', '16040028060', '16040028032',\n",
       "       '16040028090', '16040061049', '16040064009', '16040064015',\n",
       "       '16040049022', '16040049064', '16040049057', '16040049015',\n",
       "       '16040049029', '16040049010', '16040049003'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_vars = cbk.loc[~cbk['resp_cat'].str.startswith('gap',na=False),:].qtiLabel2.to_list()\n",
    "\n",
    "df_sql_check = df_long.loc[\n",
    "    (~pd.isnull(df_long['qtiLabel'])) & (df_long['qtiLabel'].isin(val_vars)) & (~df_long['qtiLabel'].str.endswith('T',na = False)),\n",
    "    ['login','unit_id','itemId','qtiLabel']\n",
    "].assign(dat='1').sort_values(['login','qtiLabel']).merge(\n",
    "    df_long_check[['login','qtiLabel','source']].assign(sql='1'),\n",
    "    how = 'outer',\n",
    "    on = ['login','qtiLabel']\n",
    ")\n",
    "\n",
    "conditions = [\n",
    "    df_sql_check['dat'].eq('1') & df_sql_check['sql'].eq('1'),\n",
    "    df_sql_check['dat'].eq('1') & ~df_sql_check['sql'].eq('1'),\n",
    "    ~df_sql_check['dat'].eq('1') & df_sql_check['sql'].eq('1'),\n",
    "]\n",
    "\n",
    "codes = [\n",
    "    'match',\n",
    "    'dat',\n",
    "    'sql'\n",
    "]\n",
    "\n",
    "df_sql_check['source'] = np.select(conditions,codes,'')\n",
    "df_sql_check.drop(columns = ['sql','dat'],inplace=True)\n",
    "\n",
    "df_sql_check.loc[df_sql_check['source'] != 'match',:].login.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_long.astype('string')\n",
    "df_long.loc[df_long['in_cq']=='1',:].groupby(['qtiLabel','score_code','isoalpha3']).size().unstack(fill_value=0).to_excel(f'./data/FLA_freq_Score_byCnt_{datetime.date.today().strftime('%Y%m%d')}.xlsx')\n",
    "df_long.loc[df_long['in_cq']=='1',:].groupby(['qtiLabel','score_code']).size().unstack(fill_value=0).to_excel(f'./data/FLA_freq_Score_Overall_{datetime.date.today().strftime('%Y%m%d')}.xlsx')\n",
    "df_long.loc[df_long['in_cq']=='1',:].groupby(['qtiLabel','cq_cat','isoalpha3']).size().unstack(fill_value=0).to_excel(f'./data/FLA_freq_Resp_byCnt_{datetime.date.today().strftime('%Y%m%d')}.xlsx')\n",
    "df_long.loc[df_long['in_cq']=='1',:].groupby(['qtiLabel','cq_cat']).size().unstack(fill_value=0).to_excel(f'./data/FLA_freq_Resp_Overall_{datetime.date.today().strftime('%Y%m%d')}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.load import *\n",
    "\n",
    "make_long_file(df_long, domain = 'FLA')\n",
    "make_wide_file(df_long, cbk = cbk, domain = 'FLA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
