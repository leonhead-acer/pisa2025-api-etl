{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare / Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Maple Data and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from etl.prepare import *\n",
    "\n",
    "with open('./config.yaml', 'r') as file:\n",
    "    config_data = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redshift_connector\n",
    "from etl.postgresqlschemareader import *\n",
    "\n",
    "with redshift_connector.connect(\n",
    "    host=config_data['ams']['host'],\n",
    "    database=config_data['ams']['database'],\n",
    "    user=config_data['ams']['username'],\n",
    "    password=config_data['ams']['password'],\n",
    "    timeout=999999,\n",
    "    port=5439\n",
    ") as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"SELECT table_schema, table_name\n",
    "                      FROM information_schema.tables\n",
    "                      WHERE table_schema != 'pg_catalog'\n",
    "                      AND table_schema != 'information_schema'\n",
    "                      AND table_type='BASE TABLE'\n",
    "                      ORDER BY table_schema, table_name\"\"\")\n",
    "\n",
    "        tables = cur.fetchall()\n",
    "        print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.extract import *\n",
    "from etl.transform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with postgresql_conn(params = config_data['postgresql_prod']) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # student_participants = extract_student_participants(filepath = '../maple-s3/participants_post.xlsx')\n",
    "        cur.execute(\"SELECT * FROM maple.isot_table\")\n",
    "        isot_table = pd.DataFrame(cur.fetchall())\n",
    "        cur.execute(\"SELECT * FROM maple.maple_student_post_val\")\n",
    "        student_participants = pd.DataFrame(cur.fetchall())\n",
    "\n",
    "        countries = list(student_participants.loc[student_participants['batch'] == '1',:].isoalpha3.unique())\n",
    "        nc_dat = isot_table.loc[isot_table['isoalpha3'].isin(countries)]\n",
    "        # nc_dat = extract_country_codes(filepath = './data/maple-s3/ISOT_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'etl.load' from 'd:\\\\Users\\\\leon.head\\\\Documents\\\\pisa2025-api-etl\\\\etl\\\\load.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['etl.load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = postgresql_conn(params = config_data['postgresql_prod'])\n",
    "con.autocommit = True\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting codebook data from sheet FLA_Reading_CQ\n",
      "Extracting codebook data from sheet FLA_Listening_CQ\n",
      "Codebook created for FLA\n",
      "Processing data for: AUT\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: BRN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: QCY\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for QCY\n",
      "Connection to DB closed\n",
      "Step 1: rows = 897 & columns = 9\n",
      "Step 2: rows = 897 & columns = 33\n",
      "Step 3: rows = 20945 & columns = 8\n",
      "Step 4: rows = 20945 & columns = 23\n",
      "Step 5: rows = 61431 & columns = 22\n",
      "Step 6: rows = 62153 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_QCY.json: 98.59 seconds\n",
      "Processing data for: DEU\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for DEU\n",
      "Connection to DB closed\n",
      "Step 1: rows = 1239 & columns = 9\n",
      "Step 2: rows = 1239 & columns = 33\n",
      "Step 3: rows = 28930 & columns = 8\n",
      "Step 4: rows = 28930 & columns = 23\n",
      "Step 5: rows = 84807 & columns = 22\n",
      "Step 6: rows = 85860 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_DEU.json: 172.80 seconds\n",
      "Processing data for: DNK\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for DNK\n",
      "Connection to DB closed\n",
      "Step 1: rows = 884 & columns = 9\n",
      "Step 2: rows = 884 & columns = 33\n",
      "Step 3: rows = 20683 & columns = 8\n",
      "Step 4: rows = 20683 & columns = 23\n",
      "Step 5: rows = 60779 & columns = 22\n",
      "Step 6: rows = 61520 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_DNK.json: 89.17 seconds\n",
      "Processing data for: QUK\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: QSC\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: HRV\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for HRV\n",
      "Connection to DB closed\n",
      "Step 1: rows = 1568 & columns = 9\n",
      "Step 2: rows = 1568 & columns = 33\n",
      "Step 3: rows = 36620 & columns = 8\n",
      "Step 4: rows = 36620 & columns = 23\n",
      "Step 5: rows = 107102 & columns = 22\n",
      "Step 6: rows = 108430 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_HRV.json: 168.19 seconds\n",
      "Processing data for: IDN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: IRL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: ITA\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for ITA\n",
      "Connection to DB closed\n",
      "Step 1: rows = 1287 & columns = 9\n",
      "Step 2: rows = 1287 & columns = 33\n",
      "Step 3: rows = 30098 & columns = 8\n",
      "Step 4: rows = 30098 & columns = 23\n",
      "Step 5: rows = 88223 & columns = 22\n",
      "Step 6: rows = 89260 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_ITA.json: 167.39 seconds\n",
      "Processing data for: LTU\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MAC\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MNE\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: MNG\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: NLD\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for NLD\n",
      "Connection to DB closed\n",
      "Step 1: rows = 641 & columns = 9\n",
      "Step 2: rows = 641 & columns = 33\n",
      "Step 3: rows = 14999 & columns = 8\n",
      "Step 4: rows = 14999 & columns = 23\n",
      "Step 5: rows = 43558 & columns = 22\n",
      "Step 6: rows = 44110 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_NLD.json: 66.63 seconds\n",
      "Processing data for: POL\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: PRT\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for PRT\n",
      "Connection to DB closed\n",
      "Step 1: rows = 1457 & columns = 9\n",
      "Step 2: rows = 1457 & columns = 33\n",
      "Step 3: rows = 33914 & columns = 8\n",
      "Step 4: rows = 33914 & columns = 23\n",
      "Step 5: rows = 99435 & columns = 22\n",
      "Step 6: rows = 100633 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_PRT.json: 212.59 seconds\n",
      "Processing data for: QAT\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for QAT\n",
      "Connection to DB closed\n",
      "Step 1: rows = 1341 & columns = 9\n",
      "Step 2: rows = 1341 & columns = 33\n",
      "Step 3: rows = 31275 & columns = 8\n",
      "Step 4: rows = 31275 & columns = 23\n",
      "Step 5: rows = 91732 & columns = 22\n",
      "Step 6: rows = 92793 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_QAT.json: 146.73 seconds\n",
      "Processing data for: SAU\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SGP\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SRB\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SVN\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: SWE\n",
      "Connection to DB established, searching for new records...\n",
      "JSON file created for SWE\n",
      "Connection to DB closed\n",
      "Step 1: rows = 1302 & columns = 9\n",
      "Step 2: rows = 1302 & columns = 33\n",
      "Step 3: rows = 30406 & columns = 8\n",
      "Step 4: rows = 30406 & columns = 23\n",
      "Step 5: rows = 89215 & columns = 22\n",
      "Step 6: rows = 90269 & columns = 49\n",
      "Time taken for ./data/db/fla/FLA_SWE.json: 140.65 seconds\n",
      "Processing data for: TUR\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n",
      "Processing data for: URY\n",
      "Connection to DB established, searching for new records...\n",
      "Connection to DB closed\n"
     ]
    }
   ],
   "source": [
    "import glob, time\n",
    "from etl.extract import *\n",
    "from etl.transform import *\n",
    "\n",
    "count = 0\n",
    "domain_all = [\"FLA\"]\n",
    "\n",
    "for domain in domain_all:\n",
    "    cbk = create_codebook(domain = domain)\n",
    "    \n",
    "    if(domain == 'FLA'):\n",
    "        gap_vars = True\n",
    "\n",
    "    for idr,row in nc_dat.iterrows():\n",
    "        start_time = time.time()\n",
    "        country_print = str(row['isoalpha3'])\n",
    "        print(f\"Processing data for: {country_print}\")\n",
    "\n",
    "        extract_json(domain = domain, nc_dat = row ,overwrite = True, con = postgresql_conn(params = config_data['postgresql_prod']))\n",
    "\n",
    "        filepath = f\"./data/db/{domain.lower()}/{domain}_{country_print}.json\"\n",
    "\n",
    "        if(os.path.isfile(filepath)):\n",
    "            df = read_json_file(filepath)\n",
    "            print(\"Step 1: rows = \" + str(df.shape[0]) + ' & columns = ' + str(df.shape[1]))\n",
    "            \n",
    "            df1 = explode_raw_data(df = df, nc_dat = nc_dat)\n",
    "            print(\"Step 2: rows = \" + str(df1.shape[0]) + ' & columns = ' + str(df1.shape[1]))\n",
    "\n",
    "            df3 = explode_items(df1)\n",
    "            print(\"Step 3: rows = \" + str(df3.shape[0]) + ' & columns = ' + str(df3.shape[1]))\n",
    "\n",
    "            df4 = explode_values(df3)\n",
    "            df4 = rename_variables(df4, domain = domain)\n",
    "            df4 = check_duplicates(df4)\n",
    "            df4 = replace_blank_json(df4)\n",
    "            print(\"Step 4: rows = \" + str(df4.shape[0]) + ' & columns = ' + str(df4.shape[1]))\n",
    "\n",
    "            df6 = explode_responses(df4, domain = domain)\n",
    "            if(domain == 'FLA'):\n",
    "                df6 = fla_recode_FLALDTB1002(df6)\n",
    "            if(gap_vars):\n",
    "                df6 = gap_recode(df6,cbk)\n",
    "            print(\"Step 5: rows = \" + str(df6.shape[0]) + ' & columns = ' + str(df6.shape[1]))\n",
    "\n",
    "            df8 = merge_cbk_status(df6,cbk,domain = 'FLA')\n",
    "            df8 = time_var_recode(df8)\n",
    "            df8 = score_resp_recode(df8,domain = 'FLA') \n",
    "            df8 = trailing_missing(df8,cbk=cbk)\n",
    "            df8 = cmc_item_create(df8,cbk=cbk, domain = 'FLA')\n",
    "            df9 = merge_participant_info(df8,nc_dat = nc_dat, student_participants=student_participants)\n",
    "            print(\"Step 6: rows = \" + str(df9.shape[0]) + ' & columns = ' + str(df9.shape[1]))\n",
    "\n",
    "            if(count == 0):\n",
    "                df_long = df9\n",
    "            else:\n",
    "                df_long = pd.concat([df_long,df9],axis = 0)\n",
    "            \n",
    "            count =+ 1\n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f\"Time taken for {filepath}: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        # df9.export_to_postgresql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>login</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>testQtiLabel</th>\n",
       "      <th>sessionStartTime</th>\n",
       "      <th>sessionEndTime</th>\n",
       "      <th>language</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>itemId</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>username</th>\n",
       "      <th>grade</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob_mm</th>\n",
       "      <th>dob_yy</th>\n",
       "      <th>sen</th>\n",
       "      <th>mpop1</th>\n",
       "      <th>ppart1</th>\n",
       "      <th>test_attendance</th>\n",
       "      <th>questionnaire_attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11960023044</td>\n",
       "      <td>1.720221e+12</td>\n",
       "      <td>FLA-L-4</td>\n",
       "      <td>2024-04-09 17:45:48</td>\n",
       "      <td>2024-04-09 18:06:45</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLALDGA1008</td>\n",
       "      <td>cluster1-FLAL04-item-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11960023044</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11960037034</td>\n",
       "      <td>1.711444e+12</td>\n",
       "      <td>FLA-L-4</td>\n",
       "      <td>2024-03-26 19:44:51</td>\n",
       "      <td>2024-03-26 20:10:00</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLALDGA1008</td>\n",
       "      <td>cluster1-FLAL04-item-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11960037034</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11960042007</td>\n",
       "      <td>1.711530e+12</td>\n",
       "      <td>FLA-L-4</td>\n",
       "      <td>2024-03-27 19:34:16</td>\n",
       "      <td>2024-03-27 20:07:17</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLALDGA1008</td>\n",
       "      <td>cluster1-FLAL04-item-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11960042007</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>11960011051</td>\n",
       "      <td>1.711531e+12</td>\n",
       "      <td>FLA-L-4</td>\n",
       "      <td>2024-03-27 19:51:40</td>\n",
       "      <td>2024-03-27 20:15:42</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLALDGA1008</td>\n",
       "      <td>cluster1-FLAL04-item-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11960011051</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>11960048016</td>\n",
       "      <td>1.711613e+12</td>\n",
       "      <td>FLA-L-4</td>\n",
       "      <td>2024-03-28 18:45:08</td>\n",
       "      <td>2024-03-28 19:11:19</td>\n",
       "      <td>en-ZZ</td>\n",
       "      <td>FLALDGA1008</td>\n",
       "      <td>cluster1-FLAL04-item-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11960048016</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index        login  last_update_date testQtiLabel     sessionStartTime  \\\n",
       "1     1.0  11960023044      1.720221e+12      FLA-L-4  2024-04-09 17:45:48   \n",
       "5     5.0  11960037034      1.711444e+12      FLA-L-4  2024-03-26 19:44:51   \n",
       "9     9.0  11960042007      1.711530e+12      FLA-L-4  2024-03-27 19:34:16   \n",
       "13   13.0  11960011051      1.711531e+12      FLA-L-4  2024-03-27 19:51:40   \n",
       "17   17.0  11960048016      1.711613e+12      FLA-L-4  2024-03-28 18:45:08   \n",
       "\n",
       "         sessionEndTime language      unit_id                  itemId score  \\\n",
       "1   2024-04-09 18:06:45    en-ZZ  FLALDGA1008  cluster1-FLAL04-item-1     1   \n",
       "5   2024-03-26 20:10:00    en-ZZ  FLALDGA1008  cluster1-FLAL04-item-1     0   \n",
       "9   2024-03-27 20:07:17    en-ZZ  FLALDGA1008  cluster1-FLAL04-item-1     1   \n",
       "13  2024-03-27 20:15:42    en-ZZ  FLALDGA1008  cluster1-FLAL04-item-1     1   \n",
       "17  2024-03-28 19:11:19    en-ZZ  FLALDGA1008  cluster1-FLAL04-item-1     1   \n",
       "\n",
       "    ...     username grade gender  dob_mm dob_yy sen  mpop1 ppart1  \\\n",
       "1   ...  11960023044    10      2      11   2008   0      1      1   \n",
       "5   ...  11960037034    10      1       6   2008   0      1      1   \n",
       "9   ...  11960042007    10      1       4   2008   0      1      1   \n",
       "13  ...  11960011051    10      2       6   2008   0      1      1   \n",
       "17  ...  11960048016    10      1       7   2008   0      1      1   \n",
       "\n",
       "   test_attendance questionnaire_attendance  \n",
       "1                1                        1  \n",
       "5                1                        1  \n",
       "9                1                        1  \n",
       "13               1                        1  \n",
       "17               1                        1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from test.data_quality.DataQuality import DataQuality\n",
    "from test.utils.utils import create_df_from_dq_results\n",
    "\n",
    "df_check = df_long.loc[df_long['in_cq'] == '1',:]\n",
    "df_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summ = {}\n",
    "\n",
    "conditions = [\n",
    "    df_check['db_score_code'].eq('1'),\n",
    "    df_check['db_score_code'].eq('0'),\n",
    "    df_check['db_score_code'].eq('9'),\n",
    "]\n",
    "codes = [\n",
    "    1,0,0\n",
    "]\n",
    "\n",
    "df_check_sum_score = df_check.copy(deep = True)\n",
    "df_check_sum_score['score_check'] = np.select(conditions,codes,None)\n",
    "\n",
    "df_check_sum_score = df_check_sum_score.groupby(['username','unit_id','score']).agg({'score_check':sum}).reset_index(inplace=False)\n",
    "df_check_sum_score = df_check_sum_score[~df_check_sum_score['unit_id'].isin(cbk.loc[cbk['resp_cat'].str.contains('gap',na=False)].unit_id.unique().tolist())]\n",
    "df_check_sum_score[['score','score_check']] = df_check_sum_score[['score','score_check']].apply(pd.to_numeric)\n",
    "\n",
    "df_summ_config = {\n",
    "    \"df_check_sum_score\": \"config_check_sum_score\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test.data_quality.DataQuality import DataQuality\n",
    "from test.utils.utils import create_df_from_dq_results\n",
    "\n",
    "df_summ_tab = {}\n",
    "\n",
    "for k, v in df_summ_config.items():\n",
    "    dq = DataQuality(globals()[k],config_path=f\"./test/config/config.json\")\n",
    "    dq_results = dq.run_test()\n",
    "    dq_table = create_df_from_dq_results(dq_results=dq_results)\n",
    "\n",
    "    df_summ_tab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dimension</th>\n",
       "      <th>status</th>\n",
       "      <th>expectation_type</th>\n",
       "      <th>unexpected_count</th>\n",
       "      <th>element_count</th>\n",
       "      <th>unexpected_percent</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>score; score_check</td>\n",
       "      <td>Validity</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_pair_values_to_be_equal</td>\n",
       "      <td>0</td>\n",
       "      <td>164941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>username</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_values_to_not_be_null</td>\n",
       "      <td>0</td>\n",
       "      <td>164941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>username</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_value_lengths_to_equal</td>\n",
       "      <td>0</td>\n",
       "      <td>164941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>score</td>\n",
       "      <td>Completeness</td>\n",
       "      <td>PASSED</td>\n",
       "      <td>expect_column_values_to_not_be_null</td>\n",
       "      <td>0</td>\n",
       "      <td>164941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               column     dimension  status  \\\n",
       "0  score; score_check      Validity  PASSED   \n",
       "1            username  Completeness  PASSED   \n",
       "2            username  Completeness  PASSED   \n",
       "3               score  Completeness  PASSED   \n",
       "\n",
       "                        expectation_type  unexpected_count  element_count  \\\n",
       "0  expect_column_pair_values_to_be_equal                 0         164941   \n",
       "1    expect_column_values_to_not_be_null                 0         164941   \n",
       "2   expect_column_value_lengths_to_equal                 0         164941   \n",
       "3    expect_column_values_to_not_be_null                 0         164941   \n",
       "\n",
       "   unexpected_percent  percent  \n",
       "0                 0.0    100.0  \n",
       "1                 0.0    100.0  \n",
       "2                 0.0    100.0  \n",
       "3                 0.0    100.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.loc[df_long['in_cq']=='1',:].groupby(['qtiLabel','score_code','isoalpha3']).size().unstack(fill_value=0).to_excel('./data/FLA_freq_Score_byCnt.xlsx')\n",
    "df_long.loc[df_long['in_cq']=='1',:].groupby(['qtiLabel','score_code']).size().unstack(fill_value=0).to_excel('./data/FLA_freq_Score_Overall.xlsx')\n",
    "df_long.loc[df_long['in_cq']=='1',:].groupby(['qtiLabel','cq_cat','isoalpha3']).size().unstack(fill_value=0).to_excel('./data/FLA_freq_Resp_byCnt.xlsx')\n",
    "df_long.loc[df_long['in_cq']=='1',:].groupby(['qtiLabel','cq_cat']).size().unstack(fill_value=0).to_excel('./data/FLA_freq_Resp_Overall.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.load import *\n",
    "\n",
    "make_long_file(df_long, domain = 'FLA')\n",
    "make_wide_file(df_long,cbk = cbk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
